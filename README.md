# The Coastal Cliffs Morphology Analysis Toolbox v2.0 (CCMORPH2)

The toolbox is series of Python scripts accompanied with JavaScript tool that can be utilized to analyse dynamics of coastal cliffs based on DEM from different sources such as GPS-RTK, UAVs, aerial or terrestrial LiDAR scanners. Python scripts are client-based (run locally), while Java Script tool can be run as a server-based application (in a web-browser environment).

The repository includes Python tools for automatic analysis of input data (generator-py, finder-py and analyser-py), a web tool that allows manual correction of selected coastal characteristic points (base and top of the profile), and sample data and configurations demonstrating how the tools work.

The repository also includes Jupyter notebook scripts for automatic comparison of output data (csv_compared-ipynb, csv_compared_2-ipynb, dem_compared-ipynb, figures-ipynb and figures_compared-ipynb)

## __Tools__

## ```generator-py```

The program is used to generate elevation profiles based on a given coastal DEM file (geotiff), a specified shoreline (SHP line) and a trimming area (SHP polygon). Basic parameters such as input and output data paths or transect parameters (lengths and spacing) can be set in the config.json file. Note that for a shoreline and a trimming area, in addition to *.shp files, *.prj files should be prepared, containing information about coordinate reference systems. In the configuration (shapes/coastline/dst_crs and shapes/buffer/dst_crs), you have to specify a system they are being transformed to for further calculations.

Both final results and all intermediate results are stored in separate files that can be used, for example, by finder-py, analyzer-py or click-the-coast-js 


What does the program do?
1. validates input data
2. creates or cleans directories for output and intermediate data
3. initializes the database
4. generates transects based on shoreline (```data/input/coast```)
5. creates buffers around transects and for each buffer creates a DEM based on the overall image (```data/input/dem```)
6. generates elevation profiles from transects and trimmed DEM models
7. trims profiles to the specified area (```data/input/crop```) and saves them (```data/output/profiles/cropped```)
8. saves data for profile visualization in click-the-coast-js web application (```data/output/web/geotif```, ```data/output/web/geojdon```, ```data/output/web/names```)

### configuration

The default configuration of the program can be changed by editing the ```generator-py/config.json``` file. Among other things, we can specify:
- directory paths for input data,
- directory paths for output data,
- the path to the database,
- parameters of generated transects,
- parameters of layers in the database (names, crs, ...), etc.

## ```finder-py```

The program allows you to automatically determine the base and the top of a cliff on each profile by approximating the distance between shoreline and the cliff top.
A new feature has been implemented in the methodology of the finder-py script which is called “beyond_top_buffer”. It refers to the distance between the maximum height point (top point of the cliff) to the last point determined by the algorithm. It informs how far beyond the highest point of the profile the profile itself ends (as long as we do not go beyond its maximum range).

### What does the program do?
1. reads the trimmed profiles generated by generator-py (```data/output/profiles/cropped```)
2. finds the base and the top on the profiles (choose one of the methods described in the article)
3. saves finder.csv results to two directories (```data/output/results``` and ```data/output/web/results```)
4. optionally saves calculation details for each profile for method no. 1 (```data/output/debug```) 

### configuration

- paths to the input data,
- paths to the output data,
- the selected method of determining points (1 or 2),
- optional profile smoothing parameters,
- optional debug parameters,
etc.

## ```click-the-coast-js```

A web application that visualizes elevation profiles for which the base and the top could not be automatically determined. It allows you to manually set both parameters of the profile. The profile is displayed as a line on the map (top view) and an intersection (side view). Basic parameters, such as paths, can be set in ```scripts/config.js``` file).

### What does the program do?
1. reads profile names generated by generator-py (```data/output/web/names/names.json```)
2. reads trimmed profiles (```output/web/geojson```) and BBOXes (bounding boxes) (```data/output/web/geotiff```)
3. reads information about profiles for which base and top have already been automatically determined by finder-py (```data/output/results/finder.csv```)
4. visualizes profiles without designated bases and tops and allows you to mark them manually
5. saves the results to a csv file (```data/output/web/results/manual.csv```)

**NOTE:** Click-the-coast-js is a web-based application. Practically all the application logic is executed on the client side (JavaScript). Only the saving to a file of points marked on the map is performed on the server side and requires the PHP interpreter. The application can therefore be run using any web server supporting PHP. Since the application can only refer to the directory in which it is placed, so the necessary data must be copied to and from it. The easiest way is to move a piece of the ```data/output/web``` directory hierarchy to the application directory. Remember to manually copy the ```manual.csv``` file created by the application to the original results directory so that analyzer-py can use it!

### configuration

The default configuration can be changed by editing the ```click-the-coast-js/scripts/config.js``` file. Among other things, you can set:
- path to the directory with profiles,
- path to the directory with bbox files,
- path to the file with profile names,
- map parameters,
etc.

## ```analyzer-py```

The program collects information about the bases and tops of profiles (generated automatically or marked manually) and calculates their properties such as distance, slope and volume. Parameters should be set in the ```config.json``` file.

### What does the program do?
1. reads the trimmed profiles generated by generator-py (```data/output/profiles/cropped```)
2. reads information about profiles whose base and top have already been automatically determined by finder-py (```data/output/web/results/finder.csv```)
3. reads the results of click-the-coast-js, i.e. bases and tops marked manually (```data/output/web/results/manual.csv``` - remember to copy this file after using click-the-coast-js from the web application's data directory)
4. determines profile parameters (distance, slope, volume) for designated bases and tops
5. saves the results in a csv file (```data/output/finall```)
6. saves lists of tops and bases separately to shp files (```data/output/finall```)

### configuration

- paths to the input data,
- paths to the output data,
- format of csv file with results from finder-py,
etc.

## __Notebook Scripts__

## ```csv_compared```

The script takes the generated CSV file from analyzer-py for comparison, the user can input multiple CSV files for comparison.

### What does the program do?
1. reads the morphological properties inside the CSV (```data/output/analyzer```)
2. Compares the properties between inputted CSV files
3. Saves the results of multiple CSVs in a single csv file (```OUTPUT_CSV_FOLDER, f'{field}_diff.csv'```)

## ```csv_compared_2```

The script takes the generated CSV file from analyzer-py for comparison, the user make comparison between two different CSV files.

### What does the program do?
1. reads the morphological properties inside the CSV (```data/output/analyzer```)
2. Compares the properties between both CSV files.
3. Saves the results of CSVs in a single csv file (```OUTPUT_CSV_FOLDER, f'{field}_diff.csv'```)

## ```figures```

Figures script is specifically implemented to generate graphical representations and comparisons of important cliff features such as cliff zero, top, and bottom points in multiple CSV files. The figures subcomponent marks these critical cliff features on automatically drawn lines according to the profile id in the corresponding CSV

### What does the program do?
1. Reads the important cliff features (cliff top, bottom and zero) according to the profile_id in the given CSV.
2. Generates graphical images representing the cliff features
3. Saves the images in either SVG/PNG/JPG (```(OUTPUT_FOLDER, f'{title}.cut{".zoom" if zoom else ""}.jpg')```)

## ```figures_compared```

Figures script is specifically implemented to generate graphical representations and comparisons of important cliff features such as cliff zero, top, and bottom points between two different CSV files. The figures subcomponent marks these critical cliff features on automatically drawn lines according to the profile id in the corresponding CSV

### What does the program do?
1. Reads the important cliff features (cliff top, bottom and zero) according to the profile_id in the given CSV.
2. Generates graphical images representing the cliff features in (SVG/PNG) format
3. Saves the images in either SVG/PNG/JPG (```(OUTPUT_FOLDER, f'{title}.cut{".zoom" if zoom else ""}.jpg')```)

## ```dem_compared```

A similar approach to representing cliff features is employed by this script, which generates a set of SVG/PNG/JPG images for a specified list of input cropped DEM files. The subcomponent marks the top, bottom and zero points of the cliff on the DEM raster.

### What does the program do?
1. Reads the important cliff features (cliff top, bottom and zero) according to the profile_id in the given CSV.
2. Generates graphical images with marked cliff top, bottom and zero points on a DEM raster
3. Saves the images in either SVG/PNG/JPG (```(OUTPUT_FOLDER, f'{title}.cut{".zoom" if zoom else ""}.jpg')```)

## Requirements and initialisation

Most of the tests (for both tools and auxiliary scripts) were performed on Linux Ubuntu 22.04.1 LTS using WSL2 running on Windows 11 Pro. The operation of the tools themselves was also tested on macOS Big Sur 11.7.1 and Windows 11 Pro. The Python interpreter version 3.10 was used each time, and the versions of the individual packages can be found in the requirements file.

The systems required the GDAL and Rtree tools to be installed. For Linux Ubuntu, this can be done as follows:
```
sudo apt install gdal-bin libgdal-dev python3-rtree
```

It is recommended that you use the Python Virtual Environment. This protects against version conflicts of previously installed packages. The easiest way to create and activate a virtual environment for testing is to call the following commands (Linux system) in the project root directory:

```
python3 -m venv env
source env/bin/activate
```

Install the necessary packages using the information in the requirements.txt file. Note that we must remember to enter the correct version of the previously installed GDAL tool in this file. So first check the version:

```
gdalinfo --version
```

then edit the requirements.txt file, modifying the GDAL version stored there to the version obtained in the previous step (e.g. GDAL==3.4.1). Finally, install the required packages:

```
pip install -r requirements.txt
```

In the root directory of the project, you can find the ```init.sh ```script, which, when run, performs all the above steps. It has been prepared for use on Ubuntu Linux.

```
./init.sh
```

## Examples 
Once the environment has been initialised (e.g. using the ```init.sh``` script), we can start testing the tools. Five sets of test data (same area, different periods) have been prepared for this purpose. All test data is placed in the ```demo``` directory, respectively in subdirectories ```sample_1```, ```sample_2``` and so on. Each directory contains the input data for calculations and the corresponding configuration files. The DEM files (Geotiff format) are split into parts immediately after downloading. Only after calling the ```init.sh``` script are they merged. We run the calculations using the script ```run_demo.sh```

```
./run_demo.sh
```

The script sequentially for each test set (```sample_1```, ```sample_2```, ...) copies the configuration files to the ```generator-py```, ```finder-py``` and ```analyzer-py``` programs after which it runs them in that order. The calculation can take, depending on the computer used, quite a long time. We are kept informed of the stage of the calculations that are currently being performed. The sample directories contain the input DEM, masks and coastline for each raster specifically. It also contains configuration files for ```generator-py```, ```finder-py``` and ```analyser-py```. After running the script, the output of each sample file will be saved in the respective sample directory in the output folder which will be automatically generated.

We can modify configuration files to change the behaviour of the tools. For example, a change in the generator-py/config.json file:

```
"transect": {
    "distance": 300,
```

to:

```
"transect": {
    "distance": 200,
```

it will result in transects being generated every 300 metres rather than 200 metres.

Once all the data have been correctly recalculated, we can use the tool for further analysis, namely ```figures_compared.ipynb```, ```dem_compared.ipynb``` or ```csv_compared.ipynb```, among others. The paths in these programs are set by default to the data in the demo directory, i.e. comparing the results of all 5 data sets (```sample_1```, ```sample_2```, etc.).
In order to test the operation of the ```Click-The-Coast``` application, example scripts have also been prepared. We will use the example ```demo/sample_5``` to explain how they work.

- When the script ```./run_demo.sh``` is executed, a data directories (```demo/sample_1```, ```demo/sample_2```, …, ```demo/sample_5```) will contain both the input data and the results of the ```generator-py```, ```finder-py``` and ```analyser-py``` programs. After reviewing the results of the analysis, we conclude that we would like to modify the position of the base and top in the selected profiles  point them out manually). We run the script ```./ctc-start.sh``` giving as argument the path to the data applications needed. In our example this would be:

    ```
    ./ctc-start.sh demo/sample_5/output/web
    ```

- The script creates a Docker container with our application, copies the current data to it and makes it accessible at ```http://localhost:8082```. Enter the address in the browser and use the application. Note that you need to install and run Docker to run the script correctly. The Internet must also be available while the script is running.

- When the work is finished with the application, we need to download the data from the container to the local directory. We do this with the script ```./ctc-download.sh``` to which we pass as an argument the local path to which the results from the web application are to be copied. In our example:

    ```
    ./ctc-download.sh demo/sample_5/output/web/results
    ```
    
- If we are not going to use the application, we can call the ```./ctc-finish.sh``` script, which will remove the container and image with our web application

- Calling the ```analyser-py``` application again will recalculate the results taking into account the new data from the web application.


## Notes

Most common problems are:
- no Rtree tool installed on the system,
- no GDAL tool installed on the system,
- versions conflict between the system GDAL tool and the GDAL package for Python,
- incorrectly entered paths to data in configuration files,
- incorrect datum (for example, input *.shp files with shoreline or trimming area do not have *.prj files or data in *.prj is incorrect).
